{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discretize data before used as input for synthetic generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discretize original and validation datasets before generating synthetic data, since PB does not support numerical features very well and for fair comparison of output quality use same input data for MS\n",
    "# Load the 5 original and validation dataframes to be discretized\n",
    "g = globals()\n",
    "\n",
    "for i in range(1,6):\n",
    "    dfname = 'df_ori_{}'.format(i)\n",
    "    g[dfname] = pd.read_csv('C:\\\\Users\\\\bde2002.53381\\\\Desktop\\\\master-thesis\\\\experiments\\\\data\\\\df_ori_{}.csv'.format(i))\n",
    "    \n",
    "for i in range(1,6):\n",
    "    dfname = 'df_val_{}'.format(i)\n",
    "    g[dfname] = pd.read_csv('C:\\\\Users\\\\bde2002.53381\\\\Desktop\\\\master-thesis\\\\experiments\\\\data\\\\df_val_{}.csv'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the 5 original dataframes\n",
    "all_ori_dfs = [df_ori_1, df_ori_2, df_ori_3, df_ori_4, df_ori_5]\n",
    "\n",
    "# List the 5 validation dataframes\n",
    "all_val_dfs = [df_val_1, df_val_2, df_val_3, df_val_4, df_val_5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import cut\n",
    "\n",
    "# Set bins for continuous numerical features\n",
    "# Age\n",
    "bins_years = [0, 20, 50, 70, 90, 120]\n",
    "bins_days = [i*365 for i in bins_years] \n",
    "labels_age = ['0-20','21-50','51-70','71-90','91-120']\n",
    "\n",
    "# Lymph nodes\n",
    "bins_lymphs = [-1, 0.5, 89, 1000] # 0-0.5 no lymphnodes, 0.5-89 some lymphnodes, > 89 unknown\n",
    "labels_lymphs = ['0','1-89','unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Discretize for all original dataframes\n",
    "i=1\n",
    "for df_ori in all_ori_dfs:\n",
    "    df_ori['binned_diagnosis_age'] = pd.cut(df_ori['diagnosis_age'], bins=bins_days, labels=labels_age)\n",
    "    df_ori['binned_tum_lymphnodes_pos'] = pd.cut(df_ori['tum_lymfklieren_positief_atl'], bins_lymphs, labels=labels_lymphs)\n",
    "    \n",
    "    # Drop old columns\n",
    "    df_ori.drop(columns=['tum_lymfklieren_positief_atl', 'diagnosis_age'], inplace=True)\n",
    "    \n",
    "    # Save dataframe\n",
    "    df_ori.to_csv('C:\\\\Users\\\\bde2002.53381\\\\Desktop\\\\master-thesis\\\\experiments\\\\data\\\\df_ori_{}_binned.csv'.format(i), index=False)\n",
    "    i += 1\n",
    "    \n",
    "\n",
    "i=1\n",
    "for df_val in all_val_dfs:\n",
    "    df_val['binned_diagnosis_age'] = pd.cut(df_val['diagnosis_age'], bins=bins_days, labels=labels_age)\n",
    "    df_val['binned_tum_lymphnodes_pos'] = pd.cut(df_val['tum_lymfklieren_positief_atl'], bins_lymphs, labels=labels_lymphs)\n",
    "    \n",
    "    # Drop old columns\n",
    "    df_val.drop(columns=['tum_lymfklieren_positief_atl', 'diagnosis_age'], inplace=True)\n",
    "    \n",
    "    # Save dataframe\n",
    "    df_val.to_csv('C:\\\\Users\\\\bde2002.53381\\\\Desktop\\\\master-thesis\\\\experiments\\\\data\\\\df_val_{}_binned.csv'.format(i), index=False)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the 5 discretized original dataframes to be used as input\n",
    "g = globals()\n",
    "\n",
    "for i in range(1,6):\n",
    "    dfname = 'df_ori_{}'.format(i)\n",
    "    g[dfname] = pd.read_csv('C:\\\\Users\\\\bde2002.53381\\\\Desktop\\\\master-thesis\\\\experiments\\\\data\\\\df_ori_{}_binned.csv'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the 5 different discretized original dataframes\n",
    "all_ori_dfs = [df_ori_1, df_ori_2, df_ori_3, df_ori_4, df_ori_5]\n",
    "\n",
    "# Select epsilon values\n",
    "epsilon_list = [10,1,0.1,0.01,0.001]\n",
    "epsilon_names = ['10','1','0_1','0_01','0_001']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marginal Synthesizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cannot import synthesis functions (so, now in new_example_1)\n",
    "from synthesis.hist_synthesis import MarginalSynthesizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "for df_ori in all_ori_dfs:\n",
    "    j=0\n",
    "    for epsilon in epsilon_list:\n",
    "        for versie in range(1,6):\n",
    "            ms = MarginalSynthesizer(epsilon=epsilon, verbose=0) # Set verbose to 0 to reduce print statements\n",
    "            ms.fit(df_ori)\n",
    "            df_syn = ms.transform(df_ori)\n",
    "            df_syn.to_csv('C:\\\\Users\\\\bde2002.53381\\\\Desktop\\\\master-thesis\\\\experiments\\\\data\\\\ms_df_syn_{}_e{}_v{}.csv'.format(i, epsilon_names[j], versie), index=False)\n",
    "        j+=1\n",
    "    i+=1        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PrivBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cannot import synthesis functions  (so, now in example_2)\n",
    "from synthesis.bayes_synthesis import PrivBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "for df_ori in all_ori_dfs:\n",
    "    j=0\n",
    "    for epsilon in epsilon_list:\n",
    "        for versie in range(1,6):\n",
    "            pb = PrivBayes(epsilon=epsilon, verbose=0) # Set verbose to 0 to reduce print statements\n",
    "            pb.fit(df_ori)\n",
    "            df_syn = pb.transform(df_ori)\n",
    "            df_syn.to_csv('C:\\\\Users\\\\bde2002.53381\\\\Desktop\\\\master-thesis\\\\experiments\\\\data\\\\pb_df_syn_{}_e{}_v{}.csv'.format(i, epsilon_names[j], versie), index=False)\n",
    "        j+=1\n",
    "    i+=1  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
